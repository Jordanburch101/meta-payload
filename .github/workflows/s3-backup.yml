name: Backup S3 to Dropbox

on:
  schedule:
    - cron: "0 0 * * *" # Runs daily at midnight UTC

jobs:
  backup:
    runs-on: ubuntu-latest

    env:
      S3_ENDPOINT: 'https://vfmxvvugriytncpzypvm.supabase.co/storage/v1/s3'
      S3_REGION: 'ap-southeast-2'
      BACKUP_RETENTION_DAYS: 30
      BETTER_STACK_HEARTBEAT: 'https://uptime.betterstack.com/api/v1/heartbeat/PgcWvW8C3Navz8Eo3aYC1WF4'

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install boto3 dropbox

      - name: Run backup script
        env:
          DROPBOX_APP_KEY: ${{ secrets.DROPBOX_APP_KEY }}
          DROPBOX_APP_SECRET: ${{ secrets.DROPBOX_APP_SECRET }}
          DROPBOX_REFRESH_TOKEN: ${{ secrets.DROPBOX_REFRESH_TOKEN }}
          S3_ACCESS_KEY_ID: ${{ secrets.S3_ACCESS_KEY_ID }}
          S3_SECRET_ACCESS_KEY: ${{ secrets.S3_SECRET_ACCESS_KEY }}
          S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }}
        run: |
          python <<EOF
import boto3
import dropbox
import os
from datetime import datetime, timedelta

# S3 client setup
s3_client = boto3.client(
    's3',
    endpoint_url=os.getenv('S3_ENDPOINT'),
    aws_access_key_id=os.getenv('S3_ACCESS_KEY_ID'),
    aws_secret_access_key=os.getenv('S3_SECRET_ACCESS_KEY'),
    region_name=os.getenv('S3_REGION')
)

# Dropbox client setup
db_client = dropbox.Dropbox(
    app_key=os.getenv('DROPBOX_APP_KEY'),
    app_secret=os.getenv('DROPBOX_APP_SECRET'),
    oauth2_refresh_token=os.getenv('DROPBOX_REFRESH_TOKEN')
)

bucket_name = os.getenv('S3_BUCKET_NAME')
backup_retention_days = int(os.getenv('BACKUP_RETENTION_DAYS'))
date_str = datetime.utcnow().strftime('%Y-%m-%d_%H-%M-%S')
backup_folder = f'/backups/{bucket_name}/{date_str}/'

# Backup S3 objects
print("Starting backup...")
for obj in s3_client.list_objects_v2(Bucket=bucket_name)['Contents']:
    key = obj['Key']
    local_file = f"/tmp/{key.replace('/', '_')}"
    s3_client.download_file(bucket_name, key, local_file)

    with open(local_file, 'rb') as f:
        db_client.files_upload(f.read(), f"{backup_folder}{key}")

    os.remove(local_file)

# Remove old backups from Dropbox
print("Removing old backups...")
retention_date = datetime.utcnow() - timedelta(days=backup_retention_days)
for entry in db_client.files_list_folder(f'/backups/{bucket_name}').entries:
    if isinstance(entry, dropbox.files.FolderMetadata):
        folder_date = datetime.strptime(entry.name, '%Y-%m-%d_%H-%M-%S')
        if folder_date < retention_date:
            db_client.files_delete_v2(entry.path_lower)

# Send heartbeat
print("Sending heartbeat...")
import requests
try:
    requests.get(os.getenv('BETTER_STACK_HEARTBEAT'))
    print("Heartbeat sent successfully.")
except Exception as e:
    print("Failed to send heartbeat:", e)
    requests.get(f"{os.getenv('BETTER_STACK_HEARTBEAT')}/fail")
EOF
